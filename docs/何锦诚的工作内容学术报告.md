# 何锦诚的工作内容学术报告

## 五、Doubao 1.5 Vision Pro 32k + Few Shot 相关工作

在完成上述一系列研究后，为进一步提升模型在表格问答任务中的性能表现，本人尝试将 few-shot 学习策略与 doubao-1.5-vision-pro-32k 模型相结合，对提示词进行优化。

在实验过程中，针对测试集进行了 5 次独立测试，每次随机抽取 100 个案例样本。经严格计算与统计，模型准确率（ACC）的平均值达到 71.20%，该结果为目前在测试集上所取得的最优成绩。具体所采用的提示词代码如下：



```
const prompt = {

&#x20; get system() {

&#x20;   return "You are an accurate table Q\&A assistant.";

&#x20; },

&#x20; generateUserPrompt: (tableText, statement) =>

&#x20;   \`Please carefully analyze the following table and answer the questions accurately. Note: Only output the answers, do not explain the process.

Example 1:

Question: who was the first cyclist to finish?

Table Content: rank,cyclist,team,time,uci protour\npoints,1,alejandro valverde (esp),caisse d'epargne,5h 29' 10",40,2,alexandr kolobnev (rus),team csc saxo bank,s.t.,30,3,davide rebellin (ita),gerolsteiner,s.t.,25,4,paolo bettini (ita),quick step,s.t.,20,5,franco pellizotti (ita),liquigas,s.t.,15,6,denis menchov (rus),rabobank,s.t.,11,7,samuel sánchez (esp),euskaltel-euskadi,s.t.,7,8,stéphane goubert (fra),ag2r-la mondiale,+ 2",5,9,haimar zubeldia (esp),euskaltel-euskadi,+ 2",3,10,david moncoutié (fra),cofidis,+ 2",1

Answer: Alejandro Valverde

Example 2:

Question: what show was he in before running man

Table Content: \[\["year","title","hangul","network","further info"],\["2008","pretty boys: a wrong situation","꽃미남 아롱사태","mnet",""],\["2009","let's go dream team! season 2","출발 드림팀2","kbs2","variety show"],\["2009-10","music bank","뮤직뱅크","kbs2","music show, as mc"],\["2010-11","running man","런닝맨","sbs","variety show"],\["2011","i'm real: song joong-ki","i'm real 송중기","qtv",""],\["2011","everyone dramatic","에브리원 드라마틱","mbc",""],\["2011","made in u","메이드 인 유","jtbc","audition show, as mc"],\["2011-12","tears of the antarctic","남극의 눈물","mbc","documentary, as narrator"]]

Answer: Music Bank

Example 3:

Question: how many athletes finished race 1?

Table Content: \[\["athlete","event","race 1\\\ntime","race 2\\\ntime","total\\\ntime","total\\\nrank"],\["jóhann haraldsson","giant slalom","1:19.10","dnf","dnf","–"],\["kristinn magnússon","giant slalom","1:17.50","1:16.29","2:33.79","42"],\["björgvin björgvinsson","giant slalom","1:15.86","dnf","dnf","–"],\["kristinn magnússon","slalom","dnf","–","dnf","–"],\["björgvin björgvinsson","slalom","dnf","–","dnf","–"],\["jóhann haraldsson","slalom","56.98","1:00.19","1:57.17","28"],\["kristinn björnsson","slalom","53.05","56.76","1:49.81","21"]]

Answer: 4

Now, please answer the following question:

Table Content: \${tableText}

Question: \${statement}

Please give the answer directly.\`,

};

export default prompt;
```

上述测试过程中的详细日志分别存储于 [vision-pro-few-shot-1.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/vision-pro-few-shot-1.txt)、[vision-pro-few-shot-2.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/vision-pro-few-shot-2.txt)、[vision-pro-few-shot-3.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/vision-pro-few-shot-3.txt)、[vision-pro-few-shot-4.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/vision-pro-few-shot-4.txt)、[vision-pro-few-shot-5.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/vision-pro-few-shot-5.txt) 文件中，这些日志为后续的数据分析与模型优化提供了详实的依据。

通过对测试结果进行深入分析可知，doubao-1.5-vision-pro-32k 模型在处理表格数据方面展现出良好的性能，能够准确识别表格结构，并依据所提供的信息生成有效的答案。同时，few-shot 提示词在该模型上的应用效果显著，相较于规则提示词，其在测试集上的表现更优。这一结果表明，结合视觉模型与 few-shot 学习策略的方法，能够充分发挥两者的优势，有效提升模型在表格问答任务中的准确率。

为进一步验证该组合方案的有效性与稳定性，本人对整个测试集进行了全面测试。测试集共计包含 4344 个测试样本，测试次数为 1 次。经统计，模型正确回答的样本数量为 3097 个，测试总时长为 4420.90 秒，准确率（ACC）达到 71.29%，测试日志存储于 [vision-pro-few-shot-all.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/vision-pro-few-shot-all.txt) 文件中。此结果进一步证明了将 few-shot 提示词应用于 doubao-1.5-vision-pro-32k 模型，能够获得更为理想的性能表现，为后续相关研究与应用提供了重要的实践依据。

## 六、SFT + Lora 相关工作

### （一）使用 200 个训练集样本 + 20 个验证集样本微调

在探索模型优化的不同路径过程中，本人尝试采用监督微调（Supervised Fine-Tuning，SFT）技术，并结合低秩自适应（Low-Rank Adaptation，Lora）方法对模型进行精调。基于字节跳动的火山方舟平台，选择 doubao-lite-32k 模型作为微调对象。

在确定微调方案时，因将整个训练集纳入火山方舟微调任务所需成本过高（预计花费数百元），故综合考虑实际情况与资源限制，最终选取 200 个训练样本和 20 个验证样本开展微调实验。

在实验操作中，严格按照平台操作流程与相关技术规范进行。经过 15 分 27 秒的训练时长，完成模型训练并成功导出。随后，针对测试集进行 5 次测试，每次随机抽取 100 个案例，且测试过程中仅使用系统提示词。经计算，模型准确率（ACC）的平均值仅为 36.4%。深入分析可知，训练样本数量过少是导致该结果的主要原因，这使得模型无法充分学习数据特征，进而严重影响其泛化能力。此次测试的详细日志分别记录于 [sft-2-1.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/sft-2-1.txt)、[sft-2-2.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/sft-2-2.txt)、[sft-2-3.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/sft-2-3.txt)、[sft-2-4.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/sft-2-4.txt)、[sft-2-5.txt](https://github.com/JacksonHe04/smart-table-llm/blob/main/llm-api/logs/sft-2-5.txt) 文件中，为后续调整优化模型微调策略提供了关键参考。

### （二）测试结果分析与总结

为全面、直观地呈现不同模型、方法在各项测试中的性能表现，现将测试结果整理成如下表格：



| 模型                        | 方法             | ACC    | 测试样本数 | 测试次数 | 备注                 |
| ------------------------- | -------------- | ------ | ----- | ---- | ------------------ |
| doubao-1.5-pro-256k       | Zero-shot      | 57%    | 100   | 1    | 基础测试               |
| doubao-1.5-pro-32k        | 规则提示词 (中文)     | 62%    | 100   | 1    | 相比 Zero-shot 提升 5% |
| doubao-1.5-pro-32k        | 规则提示词 (英文)     | 63%    | 100   | 5    | 平均值 61.60%         |
| doubao-1.5-pro-32k        | 复杂规则提示词        | 59%    | 100   | 1    | 性能反而下降             |
| doubao-1.5-pro-32k        | One-shot       | 63%    | 100   | 5    | 平均值 63%            |
| doubao-1.5-pro-32k        | One-shot (训练集) | 67%    | 300   | 1    | 在训练集上的测试           |
| doubao-lite-32k           | SFT + Lora     | 36.4%  | 100   | 5    | 由于训练样本较少，效果不理想     |
| doubao-1.5-vision-pro-32k | Zero-shot      | 69.20% | 100   | 5    | 性能提升               |
| doubao-1.5-vision-pro-32k | 规则提示词          | 70.40% | 100   | 5    | 首次突破 70%           |
| doubao-1.5-vision-pro-32k | Few-shot       | 71.20% | 100   | 5    | Vision + Few Shot  |
| doubao-1.5-vision-pro-32k | Few-shot       | 71.29% | 4344  | 1    | 在测试集全集上的测试         |

从上述表格数据可以清晰看出，在不同模型与方法的组合测试中，doubao-1.5-vision-pro-32k 模型结合 few-shot 方法在测试集上取得了最优的准确率表现。同时，也直观反映出 SFT + Lora 方法在训练样本不足的情况下，模型性能受到严重制约。这些结果不仅为本次研究提供了全面的总结，更为后续进一步探索模型优化方向、改进实验方案提供了重要的数据支撑与理论依据，有助于推动在表格问答任务领域的研究不断深入发展。

这份报告全面梳理了工作成果与发现。你若觉得某些部分需补充细节，或有其他修改意见，欢迎随时告诉我。